{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"left\">\n",
    "<img src=\"images/dask_horizontal.svg\" width=\"45%\" alt=\"Dask logo\\\"> <img src=\"images/numba_horizontal.svg\" vspace=\"50\" width=\"45%\" alt=\"Numba logo\\\">\n",
    "</p>\n",
    "\n",
    "<h1><center>Using Dask (and Numba) to Explore Chicago Taxi Trips</center></h1>\n",
    "\n",
    "## Anirrudh Krishnan\n",
    "### Software Engineer, Quansight\n",
    "#### PyLadies Chicago Meetup - August 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import dask\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Dask?\n",
    "\n",
    "* Dask is an open source library for parallel computing in Python - helping the language scale.\n",
    "\n",
    "## Why Dask?\n",
    "\n",
    "* Large Dataset (49.63 GB) - Doesn't fit in memory!\n",
    "* Scalable on local machine - and clusters\n",
    "* Familiar API (Similar to NumPy, Pandas, SciPy, etc,), and easily implementable\n",
    "\n",
    "<h1 align=\"center\">Dask Components</h1>\n",
    "\n",
    "<img src=\"images/dask-components.svg\" hspace=\"50px\" width=\"60%\" alt=\"Dask logo\\\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Schdeuler\n",
    "\n",
    "Dask has a scheduler which is deployed in a number of ways - and can easily scale to a cluster. For the purpose of showing the\n",
    "speed of Dask, we will be executing on a single-machine, but will utilize the scheduler's ability so spread across processes and threads\n",
    "to speed up the process.\n",
    "\n",
    "Furthermore, there is a Dask Web UI we can use to monitor jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client \n",
    "client = Client() # Dask Scheduler Started at port 8787"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Dataframe: Stacked Pandas Dataframes\n",
    "\n",
    "While thinking about Dask Dataframes, we should think about them as a collection of Pandas dataframes. Dask dataframes can come from a variety of formats, as well as write to a variety of formats.\n",
    "\n",
    "<img src=\"images/dask-dataframe.svg\" width=\"400px\">\n",
    "\n",
    "In the sample below, we get data from a `.csv` file as normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('taxi_trips.csv')\n",
    "df.trip_start_timestamp = df.trip_start_timestamp.astype(dtype='datetime64[ns]')\n",
    "df = df[(df.fare != 0) & (df.fare != 9999.99)]\n",
    "labels = ['company', 'payment_type', 'trip_id', 'taxi_id', 'extras', 'pickup_census_tract']\n",
    "df = df.drop(labels, axis=1)\n",
    "df = df.set_index('trip_start_timestamp', shuffle='tasks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dask.dataframe.npartitions, I can peek at how many dataframes make-up\n",
    "the entire dataset.\n",
    "\n",
    "Furthermore, I computed the size of the entire dataset, and recorded that below for fun.\n",
    "\n",
    "```Python\n",
    "sz = df.size\n",
    "print(sz.compute()) # 2708641296\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are lazily evaluvated, and thus we can look at the relations between frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dropoff_centroid_longitude', 'tax', 'fare', 'dropoff_community_area',\n",
      "       'trip_total', 'tips', 'tolls', 'trip_miles', 'pickup_centroid_location',\n",
      "       'trip_end_timestamp', 'pickup_centroid_latitude',\n",
      "       'dropoff_centroid_location', 'dropoff_census_tract',\n",
      "       'pickup_centroid_longitude', 'trip_seconds',\n",
      "       'dropoff_centroid_latitude', 'pickup_community_area'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Cleansing\n",
    "\n",
    "So I cheated, and I saw some outliers while running the computation. I made the decision to drop these row based on the fact that\n",
    "they make no sense: while the trip might have taken place, in terms of the monetary calculation, it does not make sense when the\n",
    "max is 9999.99 and the min is 0.00 for the fare of the taxi - we can (probably) make the assumption that nobody paid nothing and that nobody paid\n",
    "9999.99 for a ride...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# large_future\n",
    "# future = client.submit(lambda x: x.mean().compute(), df.loc[f'2015-01-01':f'2015-12-31', 'fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15 = df.loc['2015-01-01':'2015-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare = df['fare'].groupby(df['dropoff_community_area']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "    float64\n",
       "        ...\n",
       "Name: fare, dtype: float64\n",
       "Dask Name: series-groupby-sum-agg, 64242 tasks"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def gen_futures(df, colname):\n",
    "#     \"\"\"\n",
    "#     Returns a list of futures that require computation.\n",
    "    \n",
    "#     Parameters: \n",
    "#     arg1 (dask dataframe): Dask Dataframe that has been persisted for computational purposes. \n",
    "#     arg2 (string colname): String containing the column name to be processed.\n",
    "    \n",
    "#     Returns: \n",
    "#     list: A list containing futures.\n",
    "#     \"\"\"\n",
    "#     stats = []\n",
    "#     stats.extend((df[colname].min(), df[colname].max(), df[colname].mean(),df[colname].sum()))\n",
    "#     return stats\n",
    "\n",
    "# df_15.visualize()\n",
    "# fare = gen_futures(df_15, 'fare')\n",
    "# fare\n",
    "# fares = client.gather(fare)\n",
    "# df_15 = df_15.persist()\n",
    "# df_15.visualize()\n",
    "fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future = client.persist(df_15)\n",
    "# for i in fare:\n",
    "#     i.compute()\n",
    "#     i\n",
    "# df_15.visualize()\n",
    "# fare = gen_futures(future, 'fare')\n",
    "# for i in fare: \n",
    "#     i.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_centroid_longitude</th>\n",
       "      <th>tax</th>\n",
       "      <th>fare</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>trip_total</th>\n",
       "      <th>tips</th>\n",
       "      <th>tolls</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_centroid_location</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>extras</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>pickup_centroid_latitude</th>\n",
       "      <th>dropoff_centroid_location</th>\n",
       "      <th>company</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_centroid_longitude</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>dropoff_centroid_latitude</th>\n",
       "      <th>pickup_community_area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=182</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00.000000000</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 13:30:00.000000000</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29 15:48:57.740842240</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31 23:59:59.999999999</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: loc, 182 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                              dropoff_centroid_longitude      tax     fare taxi_id payment_type dropoff_community_area trip_total     tips    tolls trip_id trip_miles pickup_centroid_location trip_end_timestamp   extras pickup_census_tract pickup_centroid_latitude dropoff_centroid_location company dropoff_census_tract pickup_centroid_longitude trip_seconds dropoff_centroid_latitude pickup_community_area\n",
       "npartitions=182                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "2015-01-01 00:00:00.000000000                    float64  float64  float64  object       object                float64    float64  float64  float64  object    float64                   object             object  float64             float64                  float64                    object  object              float64                   float64      float64                   float64               float64\n",
       "2015-01-01 13:30:00.000000000                        ...      ...      ...     ...          ...                    ...        ...      ...      ...     ...        ...                      ...                ...      ...                 ...                      ...                       ...     ...                  ...                       ...          ...                       ...                   ...\n",
       "...                                                  ...      ...      ...     ...          ...                    ...        ...      ...      ...     ...        ...                      ...                ...      ...                 ...                      ...                       ...     ...                  ...                       ...          ...                       ...                   ...\n",
       "2015-12-29 15:48:57.740842240                        ...      ...      ...     ...          ...                    ...        ...      ...      ...     ...        ...                      ...                ...      ...                 ...                      ...                       ...     ...                  ...                       ...          ...                       ...                   ...\n",
       "2015-12-31 23:59:59.999999999                        ...      ...      ...     ...          ...                    ...        ...      ...      ...     ...        ...                      ...                ...      ...                 ...                      ...                       ...     ...                  ...                       ...          ...                       ...                   ...\n",
       "Dask Name: loc, 182 tasks"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>],\n",
       " [dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>],\n",
       " [dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>],\n",
       " [dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>,\n",
       "  dd.Scalar<series-..., dtype=float64>]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def gen_statistics(df):\n",
    "#     stats = []\n",
    "#     fare = gen_futures(df, 'fare')\n",
    "#     tips = gen_futures(df, 'tips')\n",
    "#     tax = gen_futures(df, 'tax')\n",
    "#     tolls = gen_futures(df, 'tolls')\n",
    "#     stats.extend((fare, tips, tax, tolls))\n",
    "    \n",
    "#     return stats\n",
    "\n",
    "# stats_2015_list = gen_statistics(future)\n",
    "# stats_2015_list\n",
    "\n",
    "# for i in stats_2015_list:\n",
    "#     results = client.gather(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_13 = df.loc['2013-01-01':'2013-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Array: Collection of NumPy Arrays\n",
    "\n",
    "Dask Array is \n",
    "\n",
    "\n",
    "An in-depth explaintion of the code for the arr_methods: \n",
    "\n",
    "* arr.to_dask_array transforms the dataframe slice into a dask datframe to operate on.\n",
    "* keepdims=FALSE allows the matrix to be modified and reduced to a single numeric object. Otherwise, the shape would be kept intact.\n",
    "* nan(operation) allows us to look at the totals without having to account for NaN values. \n",
    "* `.compute` tells the operation to actually _compute_ in the backend. Since we are expecting a Future, we shall not worry about the Python Process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate some basic statistics \n",
    "\"\"\"\n",
    "def arr_avg(arr, col_name):\n",
    "    return dask.array.nanmean(arr[col_name].to_dask_array(), keepdims=False).compute()\n",
    "\n",
    "def arr_min(arr):\n",
    "    return dask.array.nanmin(arr, keepdims=False).compute()\n",
    "\n",
    "def arr_max(arr, col_name):\n",
    "    return dask.array.nanmax(arr[col_name].to_dask_array(), keepdims=False).compute()\n",
    "\n",
    "def arr_sum(arr):\n",
    "    return dask.array.nansum(arr, keepdims=False).compute()\n",
    "\n",
    "def gen_futures(arr):\n",
    "    \"\"\"\n",
    "    Generate a list of futures\n",
    "    that will be submitted as a list to \n",
    "    Dask workers that are going to be calculated.\n",
    "    \"\"\"\n",
    "    totals = []\n",
    "    tavg = client.submit(arr_avg, future)\n",
    "    tmin = client.submit(arr_min, df.loc['2013-01-01':'2013-12-31'].fare.to_dask_array())\n",
    "    tmin = df.fare.min\n",
    "    tmax = client.submit(arr_max, big_future)\n",
    "    tsum = client.submit(arr_sum, big_future)\n",
    "    totals.extend((tavg, tsum, tmax, tmin))\n",
    "    return totals\n",
    "# tavg = client.submit(lambda x: x., df.fare.to_dask_array())\n",
    "# tavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 223 182 141 56 1 1\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['pickup_centroid_location', 'dropoff_centroid_location'], axis=1)\n",
    "df_13 = df.loc['2013-01-01':'2013-12-31']\n",
    "df_14 = df.loc['2014-01-01':'2014-12-31']\n",
    "df_15 = df.loc['2015-01-01':'2015-12-31']\n",
    "df_16 = df.loc['2016-01-01':'2016-12-31']\n",
    "df_17 = df.loc['2017-01-01':'2017-12-31']\n",
    "df_18 = df.loc['2018-01-01':'2018-12-31']\n",
    "df_19 = df.loc['2019-01-01':'2019-12-31']\n",
    "print(df_13.npartitions,\n",
    "df_14.npartitions,\n",
    "df_15.npartitions,\n",
    "df_16.npartitions,\n",
    "df_17.npartitions,\n",
    "df_18.npartitions,\n",
    "df_19.npartitions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = client.scatter(df_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_2 = client.submit(arr_avg, future, 'fare')\n",
    "# for year in range(2013, 2020):    \n",
    "#     df_15 = df.loc[f'{year}-01-01':f'{year}-12-31']\n",
    "#     df[f''].fare.min()\n",
    "#     df[f''].fare.max()\n",
    "#     df[f''].fare.mean()\n",
    "#     df[f''].fare.sum()\n",
    "#     client.persist(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = future_2.result()\n",
    "future_3 = client.submit(arr_max, future, 'fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13 = df.loc['2013-01-01':'2013-12-31']\n",
    "df_14 = df.loc['2014-01-01':'2014-12-31']\n",
    "df_15 = df.loc['2015-01-01':'2015-12-31']\n",
    "df_16 = df.loc['2016-01-01':'2016-12-31']\n",
    "df_17 = df.loc['2017-01-01':'2017-12-31']\n",
    "df_18 = df.loc['2018-01-01':'2018-12-31']\n",
    "\n",
    "dfs = [df_13, df_!4...]\n",
    "\n",
    "for df in dfs\n",
    "    future = client.persist(df)\n",
    "    # run the rest of analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trips_2015.size.compute() = 630217112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = client.persist(df_15)\n",
    "# tavg = client.submit(arr_avg, future, 'fare')\n",
    "# 630217112/2708641296 * 776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_centroid_longitude</th>\n",
       "      <th>tax</th>\n",
       "      <th>fare</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>trip_total</th>\n",
       "      <th>tips</th>\n",
       "      <th>tolls</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_centroid_location</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>extras</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>pickup_centroid_latitude</th>\n",
       "      <th>dropoff_centroid_location</th>\n",
       "      <th>company</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_centroid_longitude</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>dropoff_centroid_latitude</th>\n",
       "      <th>pickup_community_area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=182</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00.000000000</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 13:30:00.000000000</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29 15:48:57.740842240</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31 23:59:59.999999999</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: loc, 182 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                              dropoff_centroid_longitude      tax     fare taxi_id payment_type dropoff_community_area trip_total     tips    tolls trip_id trip_miles pickup_centroid_location trip_end_timestamp   extras pickup_census_tract pickup_centroid_latitude dropoff_centroid_location company dropoff_census_tract pickup_centroid_longitude trip_seconds dropoff_centroid_latitude pickup_community_area\n",
       "npartitions=182                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "2015-01-01 00:00:00.000000000                    float64  float64  float64  object       object                float64    float64  float64  float64  object    float64                   object             object  float64             float64                  float64                    object  object              float64                   float64      float64                   float64               float64\n",
       "2015-01-01 13:30:00.000000000                        ...      ...      ...     ...          ...                    ...        ...      ...      ...     ...        ...                      ...                ...      ...                 ...                      ...                       ...     ...                  ...                       ...          ...                       ...                   ...\n",
       "...                                                  ...      ...      ...     ...          ...                    ...        ...      ...      ...     ...        ...                      ...                ...      ...                 ...                      ...                       ...     ...                  ...                       ...          ...                       ...                   ...\n",
       "2015-12-29 15:48:57.740842240                        ...      ...      ...     ...          ...                    ...        ...      ...      ...     ...        ...                      ...                ...      ...                 ...                      ...                       ...     ...                  ...                       ...          ...                       ...                   ...\n",
       "2015-12-31 23:59:59.999999999                        ...      ...      ...     ...          ...                    ...        ...      ...      ...     ...        ...                      ...                ...      ...                 ...                      ...                       ...     ...                  ...                       ...          ...                       ...                   ...\n",
       "Dask Name: loc, 182 tasks"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_15' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e14482d892ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_15' is not defined"
     ]
    }
   ],
   "source": [
    "df_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Future: arr_avg</b> <font color=\"gray\">status: </font><font color=\"black\">pending</font>, <font color=\"gray\">key: </font>arr_avg-7f15f3107e05826a43e4d803661fb75b"
      ],
      "text/plain": [
       "<Future: status: pending, key: arr_avg-7f15f3107e05826a43e4d803661fb75b>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavg.submit(arr_avg, future, 'fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short aside: Compute vs Result. \n",
    "\n",
    "In Dask, we have the ability to lazily compute everything by first building a task graph, and then submitting. \n",
    "We can utilize this to compute across multiple cores and only compute certain results when we need to. Dask extends\n",
    "the normal futures found in Python and expands that. Result returns a future, and then, that future still needs to\n",
    "be computed. In the example above, this is what is happening. \n",
    "\n",
    "`compute` allows me to actually send the computation out to the nodes. This way, we can also \"chain\" operations together before they are done.\n",
    "\n",
    "Also, output for computation was as follows (just believe me here) so I had to go ahead and clean it. \n",
    "I mean, how can a fare be 9999.99 and 0.0? Just doesn't make sense.\n",
    "```\n",
    "average: 12.800860062723588\n",
    "total: 1444691984.2\n",
    "max: 9999.99\n",
    "min: 0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/distributed/worker.py:3165: UserWarning: Large object of size 9.23 MB detected in task graph: \n",
      "  (dask.array<values, shape=(nan,), dtype=float64, chunksize=(nan,)>,)\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  % (format_bytes(len(b)), s)\n"
     ]
    }
   ],
   "source": [
    "fare = gen_futures(df_13.fare.to_dask_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Future: status: pending, key: arr_avg-d1c135ab0c3cf9371de359b4cf4bd4a3>, <Future: status: pending, key: arr_sum-df46c20d56f7466c5d64fe55fddff770>, <Future: status: pending, key: arr_max-557adfe028be676b09654f9856001cea>, <Future: status: pending, key: arr_min-6cd3650d8c3356680559177564b49b5b>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker process 5594 exited with status 1\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "print(fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can peek at, when things are computed and stored in memory, no matter how we access the object it will be finished.\n",
    "While these run in the background, and we wait to compute them a tad bit later, we will look at how to pass multiple\n",
    "parameters to a function with futures.\n",
    "\n",
    "I will calculate the same statistics for taxes, tips and tolls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax = gen_futures(df.tax.to_dask_array())\n",
    "tips = gen_futures(df.tips.to_dask_array())\n",
    "tolls = gen_futures(df.tolls.to_dask_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all of the objects that have been generated are lists of futures.\n",
    "Calling `.result()` on the objects within the lists will block _all_ processes and dedicate\n",
    "all resources to compute that result. Instead, we will use a special method: `client.gather(collection_of_futures)`\n",
    "after checking that they have all been computed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_summ = client.gather(fare)\n",
    "tax_summ = client.gather(tax)\n",
    "tips_summ = client.gather(tips)\n",
    "tolls_summ = client.gather(tolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have reduced the dataframe, let's use pandas in order to generate some small in-memory dataframes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_summ = pd.DataFrame([fare_summ, tax_summ, tips_summ, tolls_summ], index =['fare', 'tax', 'tolls', 'tips'], \n",
    "                                              columns =['Average', 'Sum', 'Max', 'Min']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting up the data in the dask dataframe by index so that we can query it and ask it to generate us cool things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016-12-07T09:30:00.000000000' '2015-03-08T15:45:00.000000000'\n",
      " '2014-04-09T19:45:00.000000000' ... '2013-06-23T16:45:00.000000000'\n",
      " '2015-11-09T09:45:00.000000000' '2015-06-30T19:15:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "print(date_arr.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_2013.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "from colorcet import fire\n",
    "from datashader import transfer_functions as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = ds.Canvas().points(trips_2013, 'dropoff_centroid_latitude', 'dropoff_centroid_longitude')\n",
    "tf.set_background(tf.shade(agg, cmap=fire),\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
